{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of Restaurant Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jieba\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1701)\n",
    "torch.manual_seed(1701)\n",
    "torch.cuda.manual_seed_all(1701)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chinese_word_cut(mytext):\n",
    "    return \" \".join(jieba.cut(mytext))\n",
    "\n",
    "def make_label(star):\n",
    "    if star > 3:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def get_custom_stopwords(stop_words_file):\n",
    "    with open(stop_words_file) as f:\n",
    "        stopwords = f.read()\n",
    "    stopwords_list = stopwords.split('\\n')\n",
    "    custom_stopwords_list = [i for i in stopwords_list]\n",
    "    return custom_stopwords_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.n_samples, self.n_features = data.shape\n",
    "        # The first column is label, the rest are the features\n",
    "        self.n_features -= 1 \n",
    "        self.feature = torch.from_numpy(data[:, :-1].astype(np.float32)).cuda() # size [n_samples, n_features]\n",
    "        self.label = torch.from_numpy(data[:, [-1]].astype(np.float32)).cuda() # size [n_samples, 1]        \n",
    "    # support indexing such that dataset[i] can be used to get i-th sample\n",
    "    def __getitem__(self, index):\n",
    "        return self.feature[index], self.label[index]\n",
    "\n",
    "    # we can call len(dataset) to return the size\n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data and add columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\Alex\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.542 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data0.csv', nrows=3000, usecols=['star','comment'])\n",
    "data['sentiment'] = data.star.apply(make_label)\n",
    "data['cut_comment'] = data.comment.apply(chinese_word_cut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['exp', 'lex', '①①', '①②', '①③', '①④', '①⑤', '①⑥', '①⑦', '①⑧', '①⑨', '①ａ', '①ｂ', '①ｃ', '①ｄ', '①ｅ', '①ｆ', '①ｇ', '①ｈ', '①ｉ', '①ｏ', '②①', '②②', '②③', '②④', '②⑤', '②⑥', '②⑦', '②⑧', '②⑩', '②ａ', '②ｂ', '②ｄ', '②ｅ', '②ｆ', '②ｇ', '②ｈ', '②ｉ', '②ｊ', '③①', '③⑩', '③ａ', '③ｂ', '③ｃ', '③ｄ', '③ｅ', '③ｆ', '③ｇ', '③ｈ', '④ａ', '④ｂ', '④ｃ', '④ｄ', '④ｅ', '⑤ａ', '⑤ｂ', '⑤ｄ', '⑤ｅ', '⑤ｆ', 'ｌｉ', 'ｚｘｆｉｔｌ'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "stop_words_file = '哈工大停用词表.txt'\n",
    "stopwords = get_custom_stopwords(stop_words_file)\n",
    "\n",
    "vect = CountVectorizer(max_df = 1.0, \n",
    "                       min_df = 1, \n",
    "                       max_features = None,\n",
    "                       token_pattern=u'(?u)\\\\b[^\\\\d\\\\W]\\\\w+\\\\b', \n",
    "                       stop_words=frozenset(stopwords))\n",
    "\n",
    "vect1 = TfidfVectorizer(#max_features = 5000,\n",
    "                       token_pattern=u'(?u)\\\\b[^\\\\d\\\\W]\\\\w+\\\\b', \n",
    "                       stop_words=frozenset(stopwords))\n",
    "X = pd.DataFrame.sparse.from_spmatrix(vect.fit_transform(data['cut_comment']), columns=vect.get_feature_names())\n",
    "#%time X = pd.DataFrame.sparse.from_spmatrix(vect1.fit_transform(data['cut_comment']), columns=vect1.get_feature_names())\n",
    "Xy = X.assign(label_y=data.sentiment)\n",
    "train, test = train_test_split(Xy.values, test_size=0.1)\n",
    "train, test = ReviewDataset(train), ReviewDataset(test)\n",
    "dataset = train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 10\n",
    "train_loader = DataLoader(dataset=dataset,\n",
    "                            batch_size=batch,\n",
    "                            shuffle=True,\n",
    "                            num_workers=0) # This gave me errors if num-workers is not 0. I don't have time to learn why.\n",
    "#dataiter = iter(train_loader)\n",
    "\n",
    "num_epochs = 3\n",
    "learning_rate = 0.1\n",
    "total_samples = len(dataset)\n",
    "n_iterations = math.ceil(total_samples/float(batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogReg(nn.Module):\n",
    "    def __init__(self, n_input_features):\n",
    "        super(LogReg, self).__init__()\n",
    "        self.linear = nn.Linear(n_input_features, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_pred = torch.sigmoid(self.linear(x)) # Label has only two categories, so sigmoid and softmax should be essentially the same.\n",
    "        return y_pred\n",
    "\n",
    "def evaluate(data, model):\n",
    "    with torch.no_grad():\n",
    "        y_predicted = model(data.feature)\n",
    "        y_predicted_cls = y_predicted.round()\n",
    "        acc = y_predicted_cls.eq(data.label).sum() / float(data.label.shape[0])\n",
    "        return acc\n",
    "\n",
    "def weight_reset(m):\n",
    "    # I grab this func from website. It is called to compare optimizers.\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        m.reset_parameters()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logreg = LogReg(train.n_features)\n",
    "model_logreg.apply(weight_reset)\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    model_logreg.to(device)\n",
    "#optimizer=torch.optim.SGD(model_logreg.parameters(), lr=learning_rate)\n",
    "#optimizer=torch.optim.Adam(model_logreg.parameters(), lr=learning_rate)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train(model, data = train_loader, num_epochs = 3, evaluate_step = 50, printacc = True):\n",
    "    pcount = 0\n",
    "    performance = np.zeros([n_iterations // evaluate_step * num_epochs,1])\n",
    "    optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (inputs, labels) in enumerate(data):\n",
    "            # Run your training process\n",
    "            y_pred = model(inputs)\n",
    "            loss = criterion(y_pred, labels)\n",
    "            # Backward pass and update\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # zero grad before new step\n",
    "            optimizer.zero_grad()\n",
    "            if printacc == True:\n",
    "                if (i+1) % evaluate_step == 0:\n",
    "                    acc_train = evaluate(train,model)\n",
    "                    acc_test = evaluate(test,model)\n",
    "                    performance[pcount]=acc_test.item() # Save performance for plots\n",
    "                    pcount +=1\n",
    "                    print(f'Epoch: {epoch+1}/{num_epochs}, Step {i+1}/{n_iterations}, loss = {loss.item():.4f}, acc = {acc_train.item():.4f}, acc_test = {acc_test.item():.4f}')\n",
    "    return performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/3, Step 50/270, loss = 0.5761, acc = 0.6715, acc_test = 0.7000\n",
      "Epoch: 1/3, Step 100/270, loss = 0.5744, acc = 0.6785, acc_test = 0.6800\n",
      "Epoch: 1/3, Step 150/270, loss = 0.4925, acc = 0.7030, acc_test = 0.6933\n",
      "Epoch: 1/3, Step 200/270, loss = 0.5320, acc = 0.7181, acc_test = 0.7033\n",
      "Epoch: 1/3, Step 250/270, loss = 0.7662, acc = 0.7670, acc_test = 0.7400\n",
      "Epoch: 2/3, Step 50/270, loss = 0.6236, acc = 0.7844, acc_test = 0.7467\n",
      "Epoch: 2/3, Step 100/270, loss = 0.6295, acc = 0.7659, acc_test = 0.7367\n",
      "Epoch: 2/3, Step 150/270, loss = 0.5185, acc = 0.7807, acc_test = 0.7467\n",
      "Epoch: 2/3, Step 200/270, loss = 0.4782, acc = 0.7904, acc_test = 0.7600\n",
      "Epoch: 2/3, Step 250/270, loss = 0.6000, acc = 0.7944, acc_test = 0.7433\n",
      "Epoch: 3/3, Step 50/270, loss = 0.5562, acc = 0.7900, acc_test = 0.7533\n",
      "Epoch: 3/3, Step 100/270, loss = 0.5017, acc = 0.7996, acc_test = 0.7533\n",
      "Epoch: 3/3, Step 150/270, loss = 0.4592, acc = 0.8167, acc_test = 0.7600\n",
      "Epoch: 3/3, Step 200/270, loss = 0.5777, acc = 0.8022, acc_test = 0.7600\n",
      "Epoch: 3/3, Step 250/270, loss = 0.6229, acc = 0.8104, acc_test = 0.7700\n",
      "Wall time: 545 ms\n"
     ]
    }
   ],
   "source": [
    "%time performance_tf = Train(model_logreg, num_epochs = 3, evaluate_step = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7567\n"
     ]
    }
   ],
   "source": [
    "acc_test = evaluate(test,model_logreg)\n",
    "print(f'Accuracy: {acc_test.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed = np.array(test.label.cpu(),dtype=object)\n",
    "expected = model_logreg(test.feature).cpu().detach().numpy().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp,fp,tn,fn=0,0,0,0\n",
    "o = observed\n",
    "e = expected\n",
    "for i in range(len(test)):\n",
    "    if o[i] == 1 and e[i] == 1:\n",
    "        tp +=1\n",
    "    if o[i] == 1 and e[i] == 0:\n",
    "        fp +=1\n",
    "    if o[i] == 0 and e[i] == 0:\n",
    "        tn +=1\n",
    "    if o[i] == 0 and e[i] == 1:\n",
    "        fn +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7566666666666667,\n",
       " 0.8412698412698413,\n",
       " 0.7871287128712872,\n",
       " 0.8132992327365729)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = (tp + tn)/(tp+fp+tn+fn)\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "accuracy,precision,recall,f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159, 30, 68, 43)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp,fp,tn,fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret(model, number):\n",
    "    name1 = []\n",
    "    param1= []\n",
    "    i = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            name1.append(name)\n",
    "            param1.append(param.data) \n",
    "    weights = param1[0].cpu()      \n",
    "    weights1, indices = torch.sort(weights, descending= True)\n",
    "    indices = indices.numpy().tolist()\n",
    "    # Top 20 words\n",
    "    print(\"Influential words in Positive Reviews:\")\n",
    "    print(\"--------------------------------------\")\n",
    "    for i in range(number):\n",
    "        #print(indices[0][i])\n",
    "        print(X.columns[indices[0][i]])\n",
    "\n",
    "    print(\"====\\n\\n\\n\")\n",
    "    # Top 20 negative words\n",
    "    print(\"Influential words in Negative Reviews:\")\n",
    "    print(\"--------------------------------------\")\n",
    "    indices[0].reverse()   \n",
    "    for i in range(number):\n",
    "        #print(indices[0][i])\n",
    "        print(X.columns[indices[0][i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpret(model_logreg,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_comment (target, label):\n",
    "    for i in range(len(data)):\n",
    "        if target in data.cut_comment[i] and data.sentiment[i] == label:\n",
    "            print (data.comment[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_comment(target = \"西湖\", label = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snownlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snownlp import SnowNLP\n",
    "def snow_result(comemnt):\n",
    "    s = SnowNLP(comemnt)\n",
    "    if s.sentiments >= 0.4:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6696666666666666\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data['snlp_result'] = data.comment.apply(snow_result)\n",
    "\n",
    "counts = 0\n",
    "for i in range(len(data)):\n",
    "    if data.snlp_result[i] == data.sentiment[i]:\n",
    "        counts+=1\n",
    "\n",
    "print(counts/len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8862962962962962\n",
      "Test accuracy: 0.7333333333333333\n",
      "Wall time: 625 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(train.feature.cpu(), train.label.cpu())\n",
    "print(f'Train accuracy: {nb.score(train.feature.cpu(), train.label.cpu())}')\n",
    "print(f'Test accuracy: {nb.score(test.feature.cpu(), test.label.cpu())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x_in):\n",
    "        intermediate_vector = F.relu(self.fc1(x_in))\n",
    "        prediction_vector = self.fc2(intermediate_vector)\n",
    "        prediction_vector = torch.sigmoid(prediction_vector)\n",
    "        \n",
    "        return prediction_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (fc1): Linear(in_features=17289, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=100, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_MLP = MLP(train.n_features, 100, 1)\n",
    "model_MLP.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (fc1): Linear(in_features=17289, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=100, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_MLP.apply(weight_reset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/3, Step 50/270, loss = 0.7647, acc = 0.6063, acc_test = 0.6300\n",
      "Epoch: 1/3, Step 100/270, loss = 0.6346, acc = 0.6193, acc_test = 0.6267\n",
      "Epoch: 1/3, Step 150/270, loss = 0.5250, acc = 0.6289, acc_test = 0.6367\n",
      "Epoch: 1/3, Step 200/270, loss = 0.5258, acc = 0.6907, acc_test = 0.6767\n",
      "Epoch: 1/3, Step 250/270, loss = 0.5775, acc = 0.7519, acc_test = 0.7033\n",
      "Epoch: 2/3, Step 50/270, loss = 0.6190, acc = 0.7752, acc_test = 0.7467\n",
      "Epoch: 2/3, Step 100/270, loss = 0.4659, acc = 0.7944, acc_test = 0.7367\n",
      "Epoch: 2/3, Step 150/270, loss = 0.5761, acc = 0.8015, acc_test = 0.7700\n",
      "Epoch: 2/3, Step 200/270, loss = 0.3583, acc = 0.8104, acc_test = 0.7700\n",
      "Epoch: 2/3, Step 250/270, loss = 0.8295, acc = 0.8278, acc_test = 0.7600\n",
      "Epoch: 3/3, Step 50/270, loss = 0.5369, acc = 0.8459, acc_test = 0.7567\n",
      "Epoch: 3/3, Step 100/270, loss = 0.6189, acc = 0.8456, acc_test = 0.7667\n",
      "Epoch: 3/3, Step 150/270, loss = 0.5653, acc = 0.8659, acc_test = 0.7433\n",
      "Epoch: 3/3, Step 200/270, loss = 0.4234, acc = 0.8826, acc_test = 0.7300\n",
      "Epoch: 3/3, Step 250/270, loss = 0.5522, acc = 0.8904, acc_test = 0.7300\n",
      "Wall time: 1.03 s\n"
     ]
    }
   ],
   "source": [
    "%time performance_mlp = Train(model_MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7533\n"
     ]
    }
   ],
   "source": [
    "acc_test = evaluate(test,model_MLP)\n",
    "print(f'Accuracy: {acc_test.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "performance1 = np.zeros(((1+n_iterations//batch)*3,9))\n",
    "logreg = LogReg(train.n_features)\n",
    "logreg.to(device)\n",
    "optimizer = []\n",
    "optimizer.append(torch.optim.SGD(logreg.parameters(), lr=learning_rate))\n",
    "optimizer.append(torch.optim.ASGD(logreg.parameters(), lr=learning_rate))\n",
    "optimizer.append(torch.optim.Adadelta(logreg.parameters(), lr=learning_rate))\n",
    "optimizer.append(torch.optim.Adagrad(logreg.parameters(), lr=learning_rate))\n",
    "optimizer.append(torch.optim.Adam(logreg.parameters(), lr=learning_rate))\n",
    "optimizer.append(torch.optim.AdamW(logreg.parameters(), lr=learning_rate))\n",
    "optimizer.append(torch.optim.Adamax(logreg.parameters(), lr=learning_rate))\n",
    "optimizer.append(torch.optim.RMSprop(logreg.parameters(), lr=learning_rate))\n",
    "optimizer.append(torch.optim.Rprop(logreg.parameters(), lr=learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(ii):\n",
    "    logreg.apply(weight_reset)\n",
    "    acc_test = evaluate(test,logreg)\n",
    "    print(f'Optimizer: {type(optimizer1)}, Accuracy: {acc_test.item():.4f}')\n",
    "    num_epochs = 3\n",
    "    pcount=0\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            # Run your training process\n",
    "            y_pred = logreg(inputs)\n",
    "            loss = criterion(y_pred, labels)\n",
    "            # Backward pass and update\n",
    "            loss.backward()\n",
    "            optimizer1.step()\n",
    "            # zero grad before new step\n",
    "            optimizer1.zero_grad()\n",
    "            if (i) % 50 == 0:\n",
    "                acc_train = evaluate(train,logreg)\n",
    "                acc_test = evaluate(test,logreg)\n",
    "                performance1[pcount,ii]=acc_test.item() # Save performance for plots\n",
    "                pcount +=1\n",
    "                print(f'Epoch: {epoch+1}/{num_epochs}, Step {i+1}/{n_iterations}, loss = {loss.item():.4f}, acc = {acc_train.item():.4f}, acc_test = {acc_test.item():.4f}')\n",
    "    #cc_test = evaluate(test,logreg)\n",
    "    #rint(f'Optimizer: {type(optimizer1)}, Accuracy: {acc_test.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(9):\n",
    "    optimizer1 = optimizer[i]\n",
    "    %time training(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = performance1[:45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = plt.figure()\n",
    "ax = fig2.add_subplot(1,1,1)\n",
    "ax.plot(performance[:,0],label = 'SGD')\n",
    "ax.plot(performance[:,1],label = 'ASGD')\n",
    "ax.plot(performance[:,2],label = 'Adadelta')\n",
    "ax.plot(performance[:,3],label = 'Adagrad')\n",
    "ax.plot(performance[:,4],label = 'Adam')\n",
    "ax.plot(performance[:,5],label = 'AdamW')\n",
    "ax.plot(performance[:,6],label = 'Adamax')\n",
    "ax.plot(performance[:,7],label = 'RMSprop')\n",
    "ax.plot(performance[:,8],label = 'Rprop')\n",
    "ax.legend()\n",
    "#ax.set_xticks([0,2,4,6,8,10,12,14,16])\n",
    "#ax.set_xticklabels(['0','100','200','300','400','500','600','700','800'])\n",
    "ax.set_xlabel('Batch')\n",
    "ax.set_ylabel('Test accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo in presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = X.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.zeros(len(vocab))\n",
    "for word in jieba.cut(input(\"Enter a review: \")):\n",
    "    if word in vocab:\n",
    "        features[vocab.index(word)] += 1\n",
    "featuretorch = torch.from_numpy(features.astype(np.float32)).cuda()\n",
    "if logreg(featuretorch).round() == 0:\n",
    "    print('negative')\n",
    "else:\n",
    "    print('positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in jieba.cut(input(\"Enter a sentence: \")):\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" \".join(jieba.cut(input(\"Enter a sentence: \"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 5)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 17290)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
